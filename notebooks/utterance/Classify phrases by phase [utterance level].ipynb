{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import pickle\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "# to import src is necessary to append the root_path to the path\n",
    "#sys.path.append(root_path)\n",
    "\n",
    "data_path = os.path.join(root_path,'data')\n",
    "results_path = os.path.join(root_path,'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_STEMMING = True\n",
    "REMOVE_STOPWORDS = True\n",
    "MINIMUM_WORDS_PER_PHRASE = 0\n",
    "GROUP = -1\n",
    "SEED = 10\n",
    "num_topics = 60\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'IBL_topic_distribution_by_utterance_with_phrase_before_and_after_time_utterance_minimum_0_words_with_stemming.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1bd5c52ff999>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'IBL_topic_distribution_by_utterance_with_phrase_before_and_after_time_utterance_minimum_0_words_with_stemming.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'IBL_topic_distribution_by_utterance_with_phrase_before_and_after_time_utterance_minimum_0_words_with_stemming.xlsx'"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('IBL_topic_distribution_by_utterance_with_phrase_before_and_after_time_utterance_minimum_0_words_with_stemming.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b666bf274d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key 1, total 474\n",
      "key 2, total 209\n",
      "key 3, total 477\n",
      "key 4, total 70\n",
      "key 5, total 653\n"
     ]
    }
   ],
   "source": [
    "the_keys = list(set(df['phase']))\n",
    "for key in the_keys:\n",
    "    n = list(df.phase.values).count(key)\n",
    "    print(\"key {}, total {}\".format(key,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set phase 1: 94\n",
      "test set phase 2: 41\n",
      "test set phase 3: 95\n",
      "test set phase 4: 14\n",
      "test set phase 5: 130\n"
     ]
    }
   ],
   "source": [
    "trainset = {}\n",
    "testset = {}\n",
    "for name, group in df.groupby(['phase']):\n",
    "    trainset[name]=[]\n",
    "    testset[name]=[]\n",
    "    n = len(group)\n",
    "    ra = random.sample(range(n),int(n*0.2))\n",
    "    print(\"test set phase {}: {}\".format(name,int(n*0.2)))\n",
    "    count = 0\n",
    "    group = group.reset_index()\n",
    "    for i,row in group.iterrows():\n",
    "        if i in ra:\n",
    "            count+=1\n",
    "            testset[name].append(row.values)\n",
    "        else:\n",
    "            trainset[name].append(row.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = list(range(1,181))+[188,189]\n",
    "filter_labels = [180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_dict(a_dict):\n",
    "    y = []\n",
    "    X = []\n",
    "    for key in a_dict:\n",
    "        rows = a_dict[key]\n",
    "        for row in rows:\n",
    "            X.append(row[filter_rows])\n",
    "            y.append(key)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = get_data_from_dict(trainset)\n",
    "X_test,y_test = get_data_from_dict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "print(y_test.count(4))\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "clf = DecisionTreeClassifier(random_state=SEED).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-output/tree_phases_5_classes.gv.pdf'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf, class_names=['1', '2','3','4','5'], out_file=None,max_depth=3)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render('test-output/tree_phases_5_classes.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 14 16  1 18]\n",
      " [ 5 14  8  1 13]\n",
      " [12 12 34  4 33]\n",
      " [ 3  3  2  0  6]\n",
      " [28 13 23  9 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.48      0.48        94\n",
      "           2       0.25      0.34      0.29        41\n",
      "           3       0.41      0.36      0.38        95\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.45      0.44      0.44       130\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       374\n",
      "   macro avg       0.32      0.32      0.32       374\n",
      "weighted avg       0.41      0.40      0.40       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train without stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.61\n",
      "Accuracy of K-NN classifier on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  5 14  0 18]\n",
      " [10 15  9  0  7]\n",
      " [31  6 28  3 27]\n",
      " [ 2  3  3  0  6]\n",
      " [37 13 20  2 58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.61      0.49        94\n",
      "           2       0.36      0.37      0.36        41\n",
      "           3       0.38      0.29      0.33        95\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.50      0.45      0.47       130\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       374\n",
      "   macro avg       0.33      0.34      0.33       374\n",
      "weighted avg       0.41      0.42      0.41       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GNB classifier on training set: 0.24\n",
      "Accuracy of GNB classifier on test set: 0.18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 27 14 44  4]\n",
      " [ 5 14  6 14  2]\n",
      " [ 3 17 25 44  6]\n",
      " [ 1  2  1  9  1]\n",
      " [11 26 27 52 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.05      0.08        94\n",
      "           2       0.16      0.34      0.22        41\n",
      "           3       0.34      0.26      0.30        95\n",
      "           4       0.06      0.64      0.10        14\n",
      "           5       0.52      0.11      0.18       130\n",
      "\n",
      "   micro avg       0.18      0.18      0.18       374\n",
      "   macro avg       0.26      0.28      0.18       374\n",
      "weighted avg       0.34      0.18      0.19       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = gnb.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.78\n",
      "Accuracy of SVM classifier on test set: 0.49\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovr',gamma=1,kernel='rbf',random_state=SEED,C= 100.0)#class_weight={1:0.8,2:0.4,3:0.7,5:1})\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  3  7  0 19]\n",
      " [ 7 10  4  0 20]\n",
      " [25  3 29  1 37]\n",
      " [ 1  2  2  0  9]\n",
      " [27 10 15  0 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.69      0.59        94\n",
      "           2       0.36      0.24      0.29        41\n",
      "           3       0.51      0.31      0.38        95\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.48      0.60      0.53       130\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       374\n",
      "   macro avg       0.37      0.37      0.36       374\n",
      "weighted avg       0.47      0.49      0.46       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.53\n",
      "Accuracy of SVM classifier on test set: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(random_state=SEED,max_iter=3000)#,class_weight={1:0.4,2:0.4,3:0.4,4:0.5,5:0.3})\n",
    "svc.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svc.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60  2 10  0 22]\n",
      " [11  5  2  1 22]\n",
      " [26  0 30  0 39]\n",
      " [ 1  0  3  0 10]\n",
      " [30  5  4  0 91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.64      0.54        94\n",
      "           2       0.42      0.12      0.19        41\n",
      "           3       0.61      0.32      0.42        95\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.49      0.70      0.58       130\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       374\n",
      "   macro avg       0.40      0.36      0.35       374\n",
      "weighted avg       0.49      0.50      0.46       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = svc.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1000000.0, 'gamma': 1e-05} with a score of 0.51\n"
     ]
    }
   ],
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(random_state=SEED), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.80\n",
      "Accuracy of SVM classifier on test set: 0.78\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovr',gamma=1e-05,C= 1000000.0, random_state=42)#random_state=SEED,class_weight={1:0.8,2:0.4,3:0.7,5:1})\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[264  16]\n",
      " [ 68  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86       280\n",
      "           1       0.62      0.28      0.38        94\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       374\n",
      "   macro avg       0.71      0.61      0.62       374\n",
      "weighted avg       0.75      0.78      0.74       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_dict_filter(a_dict,filter_phase):\n",
    "    y = []\n",
    "    X = []\n",
    "    for key in a_dict:\n",
    "        rows = a_dict[key]\n",
    "        for row in rows:\n",
    "            X.append(row[filter_rows])\n",
    "            if filter_phase == key:\n",
    "                y.append(key)\n",
    "            else:\n",
    "                y.append(0)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset,testset = split_sets_key(clean_phrases,1)\n",
    "X_train,y_train = get_data_from_dict_filter(trainset,1)\n",
    "X_test,y_test = get_data_from_dict_filter(testset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.75\n",
      "Accuracy of SVM classifier on test set: 0.70\n",
      "[[206  74]\n",
      " [ 37  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79       280\n",
      "           1       0.44      0.61      0.51        94\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       374\n",
      "   macro avg       0.64      0.67      0.65       374\n",
      "weighted avg       0.74      0.70      0.72       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovr',gamma=1e-05,C= 10000000.0, random_state=SEED,class_weight={0:0.3,1:0.7})\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset,testset = split_sets_key(clean_phrases,2)\n",
    "X_train,y_train = get_topic_distribution(trainset)\n",
    "X_test,y_test = get_topic_distribution(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.97\n",
      "Accuracy of SVM classifier on test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovo',gamma=10,C= 1000.0, random_state=42)#random_state=SEED,class_weight={1:0.8,2:0.4,3:0.7,5:1})\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[310  27]\n",
      " [ 31  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       337\n",
      "           2       0.29      0.26      0.28        42\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       379\n",
      "   macro avg       0.60      0.59      0.59       379\n",
      "weighted avg       0.84      0.85      0.84       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset,testset = split_sets_key(clean_phrases,3)\n",
    "X_train,y_train = get_topic_distribution(trainset)\n",
    "X_test,y_test = get_topic_distribution(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.94\n",
      "Accuracy of SVM classifier on test set: 0.72\n",
      "[[238  45]\n",
      " [ 61  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       283\n",
      "           3       0.44      0.36      0.40        96\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       379\n",
      "   macro avg       0.62      0.60      0.61       379\n",
      "weighted avg       0.71      0.72      0.71       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovo',gamma=10,C= 1000.0, random_state=42)#random_state=SEED,class_weight={1:0.8,2:0.4,3:0.7,5:1})\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify class 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.94\n",
      "Accuracy of SVM classifier on test set: 0.72\n",
      "[[232  51]\n",
      " [ 54  42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       283\n",
      "           3       0.45      0.44      0.44        96\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       379\n",
      "   macro avg       0.63      0.63      0.63       379\n",
      "weighted avg       0.72      0.72      0.72       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset,testset = split_sets_key(clean_phrases,3)\n",
    "X_train,y_train = get_topic_distribution(trainset)\n",
    "X_test,y_test = get_topic_distribution(testset)\n",
    "svm = SVC(decision_function_shape='ovo',gamma=10,C= 1000.0, random_state=42)#random_state=SEED,class_weight={1:0.8,2:0.4,3:0.7,5:1})\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.20314547837484\n"
     ]
    }
   ],
   "source": [
    "trainset,testset = split_sets_key(clean_phrases,5)\n",
    "X_train,y_train = get_topic_distribution(trainset)\n",
    "X_test,y_test = get_topic_distribution(testset)\n",
    "print(y_train.count(0)*100.0/len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.91\n",
      "Accuracy of SVM classifier on test set: 0.58\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(decision_function_shape='ovo',gamma=10,C= 1000.0, random_state=SEED)#,class_weight={5:0.7,0:0.3})#,3:0.7,5:1})\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180  67]\n",
      " [ 92  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69       247\n",
      "           5       0.37      0.30      0.33       132\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       379\n",
      "   macro avg       0.52      0.52      0.51       379\n",
      "weighted avg       0.56      0.58      0.57       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42,class_weight={0:0.36,5:0.63}).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48809521, 0.51190479],\n",
       "       [0.47908077, 0.52091923],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.50150163, 0.49849837],\n",
       "       [0.53557416, 0.46442584],\n",
       "       [0.54171687, 0.45828313],\n",
       "       [0.53040496, 0.46959504],\n",
       "       [0.52168871, 0.47831129],\n",
       "       [0.55859212, 0.44140788],\n",
       "       [0.53143153, 0.46856847],\n",
       "       [0.50047013, 0.49952987],\n",
       "       [0.45217879, 0.54782121],\n",
       "       [0.50560881, 0.49439119],\n",
       "       [0.51346373, 0.48653627],\n",
       "       [0.48517514, 0.51482486],\n",
       "       [0.53966207, 0.46033793],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.52508409, 0.47491591],\n",
       "       [0.50422179, 0.49577821],\n",
       "       [0.48598265, 0.51401735],\n",
       "       [0.52190851, 0.47809149],\n",
       "       [0.48753983, 0.51246017],\n",
       "       [0.54060426, 0.45939574],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.45897801, 0.54102199],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.56737279, 0.43262721],\n",
       "       [0.55260755, 0.44739245],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.5319106 , 0.4680894 ],\n",
       "       [0.49261257, 0.50738743],\n",
       "       [0.51303117, 0.48696883],\n",
       "       [0.53396916, 0.46603084],\n",
       "       [0.49933156, 0.50066844],\n",
       "       [0.53986637, 0.46013363],\n",
       "       [0.45527352, 0.54472648],\n",
       "       [0.51612881, 0.48387119],\n",
       "       [0.51678401, 0.48321599],\n",
       "       [0.54562846, 0.45437154],\n",
       "       [0.51001722, 0.48998278],\n",
       "       [0.50082482, 0.49917518],\n",
       "       [0.54832035, 0.45167965],\n",
       "       [0.49491845, 0.50508155],\n",
       "       [0.51303133, 0.48696867],\n",
       "       [0.46872325, 0.53127675],\n",
       "       [0.54442762, 0.45557238],\n",
       "       [0.48720981, 0.51279019],\n",
       "       [0.55375794, 0.44624206],\n",
       "       [0.5324706 , 0.4675294 ],\n",
       "       [0.5055564 , 0.4944436 ],\n",
       "       [0.48848679, 0.51151321],\n",
       "       [0.56746576, 0.43253424],\n",
       "       [0.55347321, 0.44652679],\n",
       "       [0.53820438, 0.46179562],\n",
       "       [0.53184016, 0.46815984],\n",
       "       [0.54890827, 0.45109173],\n",
       "       [0.49689266, 0.50310734],\n",
       "       [0.53094393, 0.46905607],\n",
       "       [0.50913319, 0.49086681],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.50800362, 0.49199638],\n",
       "       [0.51337731, 0.48662269],\n",
       "       [0.53226945, 0.46773055],\n",
       "       [0.5251639 , 0.4748361 ],\n",
       "       [0.45379702, 0.54620298],\n",
       "       [0.4876313 , 0.5123687 ],\n",
       "       [0.50265238, 0.49734762],\n",
       "       [0.49635693, 0.50364307],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.56442324, 0.43557676],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.48432772, 0.51567228],\n",
       "       [0.52494732, 0.47505268],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.53013804, 0.46986196],\n",
       "       [0.52508416, 0.47491584],\n",
       "       [0.51947598, 0.48052402],\n",
       "       [0.51224252, 0.48775748],\n",
       "       [0.46815096, 0.53184904],\n",
       "       [0.50525256, 0.49474744],\n",
       "       [0.54036841, 0.45963159],\n",
       "       [0.50775784, 0.49224216],\n",
       "       [0.52281419, 0.47718581],\n",
       "       [0.50216839, 0.49783161],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.48949839, 0.51050161],\n",
       "       [0.49651507, 0.50348493],\n",
       "       [0.47717383, 0.52282617],\n",
       "       [0.52609849, 0.47390151],\n",
       "       [0.5415787 , 0.4584213 ],\n",
       "       [0.51768705, 0.48231295],\n",
       "       [0.50229807, 0.49770193],\n",
       "       [0.5374822 , 0.4625178 ],\n",
       "       [0.52940517, 0.47059483],\n",
       "       [0.58045049, 0.41954951],\n",
       "       [0.51621133, 0.48378867],\n",
       "       [0.50903191, 0.49096809],\n",
       "       [0.56240593, 0.43759407],\n",
       "       [0.55782517, 0.44217483],\n",
       "       [0.52194155, 0.47805845],\n",
       "       [0.50176293, 0.49823707],\n",
       "       [0.48741822, 0.51258178],\n",
       "       [0.53717291, 0.46282709],\n",
       "       [0.47783606, 0.52216394],\n",
       "       [0.44960962, 0.55039038],\n",
       "       [0.56799489, 0.43200511],\n",
       "       [0.57706051, 0.42293949],\n",
       "       [0.53625446, 0.46374554],\n",
       "       [0.54268587, 0.45731413],\n",
       "       [0.57011976, 0.42988024],\n",
       "       [0.58305859, 0.41694141],\n",
       "       [0.51208805, 0.48791195],\n",
       "       [0.61109523, 0.38890477],\n",
       "       [0.46577938, 0.53422062],\n",
       "       [0.52026725, 0.47973275],\n",
       "       [0.47326632, 0.52673368],\n",
       "       [0.66813595, 0.33186405],\n",
       "       [0.68544515, 0.31455485],\n",
       "       [0.52080597, 0.47919403],\n",
       "       [0.62000973, 0.37999027],\n",
       "       [0.51522852, 0.48477148],\n",
       "       [0.49952067, 0.50047933],\n",
       "       [0.59729308, 0.40270692],\n",
       "       [0.51035127, 0.48964873],\n",
       "       [0.54977211, 0.45022789],\n",
       "       [0.52508424, 0.47491576],\n",
       "       [0.53716157, 0.46283843],\n",
       "       [0.59409721, 0.40590279],\n",
       "       [0.5192037 , 0.4807963 ],\n",
       "       [0.47115271, 0.52884729],\n",
       "       [0.54060426, 0.45939574],\n",
       "       [0.6344505 , 0.3655495 ],\n",
       "       [0.6835947 , 0.3164053 ],\n",
       "       [0.51963863, 0.48036137],\n",
       "       [0.69206679, 0.30793321],\n",
       "       [0.56894081, 0.43105919],\n",
       "       [0.52648879, 0.47351121],\n",
       "       [0.51662491, 0.48337509],\n",
       "       [0.46501364, 0.53498636],\n",
       "       [0.46752419, 0.53247581],\n",
       "       [0.5463868 , 0.4536132 ],\n",
       "       [0.53423481, 0.46576519],\n",
       "       [0.55291127, 0.44708873],\n",
       "       [0.54858332, 0.45141668],\n",
       "       [0.53201019, 0.46798981],\n",
       "       [0.53420518, 0.46579482],\n",
       "       [0.57137335, 0.42862665],\n",
       "       [0.58457752, 0.41542248],\n",
       "       [0.51532051, 0.48467949],\n",
       "       [0.48780032, 0.51219968],\n",
       "       [0.56845555, 0.43154445],\n",
       "       [0.48330455, 0.51669545],\n",
       "       [0.47825119, 0.52174881],\n",
       "       [0.5371904 , 0.4628096 ],\n",
       "       [0.49219489, 0.50780511],\n",
       "       [0.6513692 , 0.3486308 ],\n",
       "       [0.52772473, 0.47227527],\n",
       "       [0.49079974, 0.50920026],\n",
       "       [0.52333584, 0.47666416],\n",
       "       [0.51741598, 0.48258402],\n",
       "       [0.58452848, 0.41547152],\n",
       "       [0.62206152, 0.37793848],\n",
       "       [0.74472951, 0.25527049],\n",
       "       [0.49532982, 0.50467018],\n",
       "       [0.49575921, 0.50424079],\n",
       "       [0.48790604, 0.51209396],\n",
       "       [0.47449544, 0.52550456],\n",
       "       [0.52074006, 0.47925994],\n",
       "       [0.4832349 , 0.5167651 ],\n",
       "       [0.56866164, 0.43133836],\n",
       "       [0.51659919, 0.48340081],\n",
       "       [0.5406626 , 0.4593374 ],\n",
       "       [0.54110386, 0.45889614],\n",
       "       [0.47801102, 0.52198898],\n",
       "       [0.50174294, 0.49825706],\n",
       "       [0.50225665, 0.49774335],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.56479322, 0.43520678],\n",
       "       [0.62849729, 0.37150271],\n",
       "       [0.59023722, 0.40976278],\n",
       "       [0.50929194, 0.49070806],\n",
       "       [0.43238966, 0.56761034],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.52459343, 0.47540657],\n",
       "       [0.57048682, 0.42951318],\n",
       "       [0.64819644, 0.35180356],\n",
       "       [0.51300187, 0.48699813],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.5623877 , 0.4376123 ],\n",
       "       [0.51618026, 0.48381974],\n",
       "       [0.50714794, 0.49285206],\n",
       "       [0.53006093, 0.46993907],\n",
       "       [0.53868213, 0.46131787],\n",
       "       [0.49058048, 0.50941952],\n",
       "       [0.53780825, 0.46219175],\n",
       "       [0.52058435, 0.47941565],\n",
       "       [0.48683394, 0.51316606],\n",
       "       [0.5697219 , 0.4302781 ],\n",
       "       [0.51354798, 0.48645202],\n",
       "       [0.50399942, 0.49600058],\n",
       "       [0.52375035, 0.47624965],\n",
       "       [0.52274734, 0.47725266],\n",
       "       [0.53261565, 0.46738435],\n",
       "       [0.51567883, 0.48432117],\n",
       "       [0.46279193, 0.53720807],\n",
       "       [0.4508937 , 0.5491063 ],\n",
       "       [0.52528774, 0.47471226],\n",
       "       [0.40049635, 0.59950365],\n",
       "       [0.48920744, 0.51079256],\n",
       "       [0.51008628, 0.48991372],\n",
       "       [0.48327884, 0.51672116],\n",
       "       [0.47306821, 0.52693179],\n",
       "       [0.59196656, 0.40803344],\n",
       "       [0.52497778, 0.47502222],\n",
       "       [0.53611972, 0.46388028],\n",
       "       [0.53619767, 0.46380233],\n",
       "       [0.54359523, 0.45640477],\n",
       "       [0.52321989, 0.47678011],\n",
       "       [0.48272756, 0.51727244],\n",
       "       [0.53587522, 0.46412478],\n",
       "       [0.51838173, 0.48161827],\n",
       "       [0.55628082, 0.44371918],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.55035145, 0.44964855],\n",
       "       [0.47422877, 0.52577123],\n",
       "       [0.49374429, 0.50625571],\n",
       "       [0.52809839, 0.47190161],\n",
       "       [0.50411417, 0.49588583],\n",
       "       [0.55638689, 0.44361311],\n",
       "       [0.52672161, 0.47327839],\n",
       "       [0.58215984, 0.41784016],\n",
       "       [0.58587429, 0.41412571],\n",
       "       [0.56636853, 0.43363147],\n",
       "       [0.54272227, 0.45727773],\n",
       "       [0.50794265, 0.49205735],\n",
       "       [0.49866629, 0.50133371],\n",
       "       [0.51087565, 0.48912435],\n",
       "       [0.53737613, 0.46262387],\n",
       "       [0.49860605, 0.50139395],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.48367704, 0.51632296],\n",
       "       [0.50905087, 0.49094913],\n",
       "       [0.48241371, 0.51758629],\n",
       "       [0.50719268, 0.49280732],\n",
       "       [0.53084158, 0.46915842],\n",
       "       [0.53736336, 0.46263664],\n",
       "       [0.5250841 , 0.4749159 ],\n",
       "       [0.48919297, 0.51080703],\n",
       "       [0.49578788, 0.50421212],\n",
       "       [0.53100849, 0.46899151],\n",
       "       [0.51852284, 0.48147716],\n",
       "       [0.47090914, 0.52909086],\n",
       "       [0.47530603, 0.52469397],\n",
       "       [0.45062685, 0.54937315],\n",
       "       [0.52932946, 0.47067054],\n",
       "       [0.52508412, 0.47491588],\n",
       "       [0.53462054, 0.46537946],\n",
       "       [0.50842961, 0.49157039],\n",
       "       [0.4926747 , 0.5073253 ],\n",
       "       [0.57251152, 0.42748848],\n",
       "       [0.63311689, 0.36688311],\n",
       "       [0.52115658, 0.47884342],\n",
       "       [0.47164871, 0.52835129],\n",
       "       [0.48665844, 0.51334156],\n",
       "       [0.5266673 , 0.4733327 ],\n",
       "       [0.48100545, 0.51899455],\n",
       "       [0.52582046, 0.47417954],\n",
       "       [0.55893534, 0.44106466],\n",
       "       [0.46503037, 0.53496963],\n",
       "       [0.47864892, 0.52135108],\n",
       "       [0.44816984, 0.55183016],\n",
       "       [0.45081179, 0.54918821],\n",
       "       [0.50902225, 0.49097775],\n",
       "       [0.47814298, 0.52185702],\n",
       "       [0.52849005, 0.47150995],\n",
       "       [0.46063669, 0.53936331],\n",
       "       [0.48526003, 0.51473997],\n",
       "       [0.54262294, 0.45737706],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.50665283, 0.49334717],\n",
       "       [0.49327144, 0.50672856],\n",
       "       [0.49628888, 0.50371112],\n",
       "       [0.48049865, 0.51950135],\n",
       "       [0.45588383, 0.54411617],\n",
       "       [0.53424843, 0.46575157],\n",
       "       [0.51768702, 0.48231298],\n",
       "       [0.49623089, 0.50376911],\n",
       "       [0.52137469, 0.47862531],\n",
       "       [0.52237167, 0.47762833],\n",
       "       [0.48631698, 0.51368302],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.55039089, 0.44960911],\n",
       "       [0.50451435, 0.49548565],\n",
       "       [0.51844449, 0.48155551],\n",
       "       [0.52724238, 0.47275762],\n",
       "       [0.45948362, 0.54051638],\n",
       "       [0.50922646, 0.49077354],\n",
       "       [0.5821233 , 0.4178767 ],\n",
       "       [0.47543161, 0.52456839],\n",
       "       [0.52074015, 0.47925985],\n",
       "       [0.54051506, 0.45948494],\n",
       "       [0.45195922, 0.54804078],\n",
       "       [0.46153585, 0.53846415],\n",
       "       [0.49844206, 0.50155794],\n",
       "       [0.51036604, 0.48963396],\n",
       "       [0.54938814, 0.45061186],\n",
       "       [0.49428965, 0.50571035],\n",
       "       [0.50923849, 0.49076151],\n",
       "       [0.4662041 , 0.5337959 ],\n",
       "       [0.53361881, 0.46638119],\n",
       "       [0.53717289, 0.46282711],\n",
       "       [0.47699722, 0.52300278],\n",
       "       [0.55815442, 0.44184558],\n",
       "       [0.45978835, 0.54021165],\n",
       "       [0.52312422, 0.47687578],\n",
       "       [0.56514681, 0.43485319],\n",
       "       [0.48448689, 0.51551311],\n",
       "       [0.51186507, 0.48813493],\n",
       "       [0.52021783, 0.47978217],\n",
       "       [0.51333435, 0.48666565],\n",
       "       [0.50861213, 0.49138787],\n",
       "       [0.54286417, 0.45713583],\n",
       "       [0.48117871, 0.51882129],\n",
       "       [0.5090005 , 0.4909995 ],\n",
       "       [0.50082381, 0.49917619],\n",
       "       [0.45609033, 0.54390967],\n",
       "       [0.50299845, 0.49700155],\n",
       "       [0.46612323, 0.53387677],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.53978954, 0.46021046],\n",
       "       [0.50608965, 0.49391035],\n",
       "       [0.52673716, 0.47326284],\n",
       "       [0.51933165, 0.48066835],\n",
       "       [0.50487358, 0.49512642],\n",
       "       [0.48284476, 0.51715524],\n",
       "       [0.53638473, 0.46361527],\n",
       "       [0.50716884, 0.49283116],\n",
       "       [0.52120682, 0.47879318],\n",
       "       [0.49935137, 0.50064863],\n",
       "       [0.634509  , 0.365491  ],\n",
       "       [0.45203402, 0.54796598],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.48937928, 0.51062072],\n",
       "       [0.48127197, 0.51872803],\n",
       "       [0.50293834, 0.49706166],\n",
       "       [0.48488846, 0.51511154],\n",
       "       [0.48827467, 0.51172533],\n",
       "       [0.49971951, 0.50028049],\n",
       "       [0.54090717, 0.45909283],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.52519117, 0.47480883],\n",
       "       [0.50268136, 0.49731864],\n",
       "       [0.52190952, 0.47809048],\n",
       "       [0.39151637, 0.60848363],\n",
       "       [0.45318777, 0.54681223],\n",
       "       [0.42367537, 0.57632463],\n",
       "       [0.48847622, 0.51152378],\n",
       "       [0.46368436, 0.53631564],\n",
       "       [0.50912635, 0.49087365],\n",
       "       [0.46919663, 0.53080337],\n",
       "       [0.44912551, 0.55087449],\n",
       "       [0.45871404, 0.54128596],\n",
       "       [0.42966046, 0.57033954],\n",
       "       [0.50271144, 0.49728856],\n",
       "       [0.50039656, 0.49960344],\n",
       "       [0.52501799, 0.47498201],\n",
       "       [0.5506789 , 0.4493211 ],\n",
       "       [0.5337186 , 0.4662814 ],\n",
       "       [0.48140587, 0.51859413],\n",
       "       [0.49483766, 0.50516234],\n",
       "       [0.48716776, 0.51283224],\n",
       "       [0.48554671, 0.51445329],\n",
       "       [0.53290125, 0.46709875],\n",
       "       [0.51352484, 0.48647516],\n",
       "       [0.50548326, 0.49451674],\n",
       "       [0.55628082, 0.44371918],\n",
       "       [0.54688779, 0.45311221],\n",
       "       [0.49669066, 0.50330934],\n",
       "       [0.50555673, 0.49444327]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[188  59]\n",
      " [ 75  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       247\n",
      "           5       0.49      0.43      0.46       132\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       379\n",
      "   macro avg       0.60      0.60      0.60       379\n",
      "weighted avg       0.64      0.65      0.64       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04929037263788723"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51722492, 0.48277508],\n",
       "       [0.51802061, 0.48197939],\n",
       "       [0.48140675, 0.51859325],\n",
       "       [0.43863162, 0.56136838],\n",
       "       [0.48832214, 0.51167786],\n",
       "       [0.50338065, 0.49661935],\n",
       "       [0.49807092, 0.50192908],\n",
       "       [0.48768827, 0.51231173],\n",
       "       [0.51940268, 0.48059732],\n",
       "       [0.50682786, 0.49317214],\n",
       "       [0.53835118, 0.46164882],\n",
       "       [0.50396708, 0.49603292],\n",
       "       [0.49456355, 0.50543645],\n",
       "       [0.48788069, 0.51211931],\n",
       "       [0.49864388, 0.50135612],\n",
       "       [0.50588767, 0.49411233],\n",
       "       [0.46784628, 0.53215372],\n",
       "       [0.5014208 , 0.4985792 ],\n",
       "       [0.5039747 , 0.4960253 ],\n",
       "       [0.512218  , 0.487782  ],\n",
       "       [0.49972879, 0.50027121],\n",
       "       [0.50298627, 0.49701373],\n",
       "       [0.4973704 , 0.5026296 ],\n",
       "       [0.48707633, 0.51292367],\n",
       "       [0.49860459, 0.50139541],\n",
       "       [0.49349256, 0.50650744],\n",
       "       [0.50527679, 0.49472321],\n",
       "       [0.47977555, 0.52022445],\n",
       "       [0.52144721, 0.47855279],\n",
       "       [0.46241811, 0.53758189],\n",
       "       [0.50079269, 0.49920731],\n",
       "       [0.51449476, 0.48550524],\n",
       "       [0.49255952, 0.50744048],\n",
       "       [0.51321545, 0.48678455],\n",
       "       [0.47499819, 0.52500181],\n",
       "       [0.49674769, 0.50325231],\n",
       "       [0.52411889, 0.47588111],\n",
       "       [0.49662755, 0.50337245],\n",
       "       [0.49180874, 0.50819126],\n",
       "       [0.49784293, 0.50215707],\n",
       "       [0.50098361, 0.49901639],\n",
       "       [0.51383055, 0.48616945],\n",
       "       [0.52214281, 0.47785719],\n",
       "       [0.464827  , 0.535173  ],\n",
       "       [0.47958038, 0.52041962],\n",
       "       [0.52127326, 0.47872674],\n",
       "       [0.53042263, 0.46957737],\n",
       "       [0.46813489, 0.53186511],\n",
       "       [0.54256663, 0.45743337],\n",
       "       [0.45303235, 0.54696765],\n",
       "       [0.52559169, 0.47440831],\n",
       "       [0.52775105, 0.47224895],\n",
       "       [0.48624517, 0.51375483],\n",
       "       [0.50093724, 0.49906276],\n",
       "       [0.51375869, 0.48624131],\n",
       "       [0.48682982, 0.51317018],\n",
       "       [0.49753197, 0.50246803],\n",
       "       [0.51476121, 0.48523879],\n",
       "       [0.49420606, 0.50579394],\n",
       "       [0.45783523, 0.54216477],\n",
       "       [0.51712442, 0.48287558],\n",
       "       [0.5138797 , 0.4861203 ],\n",
       "       [0.49670127, 0.50329873],\n",
       "       [0.51180357, 0.48819643],\n",
       "       [0.51499767, 0.48500233],\n",
       "       [0.47460146, 0.52539854],\n",
       "       [0.45412183, 0.54587817],\n",
       "       [0.51791365, 0.48208635],\n",
       "       [0.48536014, 0.51463986],\n",
       "       [0.53621232, 0.46378768],\n",
       "       [0.47077668, 0.52922332],\n",
       "       [0.53472307, 0.46527693],\n",
       "       [0.51188678, 0.48811322],\n",
       "       [0.4849935 , 0.5150065 ],\n",
       "       [0.4631261 , 0.5368739 ],\n",
       "       [0.47137445, 0.52862555],\n",
       "       [0.49532792, 0.50467208],\n",
       "       [0.56326762, 0.43673238],\n",
       "       [0.53517326, 0.46482674],\n",
       "       [0.51254483, 0.48745517],\n",
       "       [0.50998852, 0.49001148],\n",
       "       [0.53287054, 0.46712946],\n",
       "       [0.5273135 , 0.4726865 ],\n",
       "       [0.52067189, 0.47932811],\n",
       "       [0.5191249 , 0.4808751 ],\n",
       "       [0.46893601, 0.53106399],\n",
       "       [0.46299528, 0.53700472],\n",
       "       [0.50710368, 0.49289632],\n",
       "       [0.53282409, 0.46717591],\n",
       "       [0.47719687, 0.52280313],\n",
       "       [0.47434987, 0.52565013],\n",
       "       [0.49803553, 0.50196447],\n",
       "       [0.52772054, 0.47227946],\n",
       "       [0.5084284 , 0.4915716 ],\n",
       "       [0.46919736, 0.53080264],\n",
       "       [0.46177031, 0.53822969],\n",
       "       [0.47268141, 0.52731859],\n",
       "       [0.49513867, 0.50486133],\n",
       "       [0.49459503, 0.50540497],\n",
       "       [0.55478348, 0.44521652],\n",
       "       [0.50956122, 0.49043878],\n",
       "       [0.497144  , 0.502856  ],\n",
       "       [0.49844343, 0.50155657],\n",
       "       [0.52025806, 0.47974194],\n",
       "       [0.53602353, 0.46397647],\n",
       "       [0.46398902, 0.53601098],\n",
       "       [0.54055656, 0.45944344],\n",
       "       [0.57033941, 0.42966059],\n",
       "       [0.49299581, 0.50700419],\n",
       "       [0.48749415, 0.51250585],\n",
       "       [0.51039112, 0.48960888],\n",
       "       [0.47877022, 0.52122978],\n",
       "       [0.53421725, 0.46578275],\n",
       "       [0.49821011, 0.50178989],\n",
       "       [0.48097645, 0.51902355],\n",
       "       [0.51753318, 0.48246682],\n",
       "       [0.5711854 , 0.4288146 ],\n",
       "       [0.50973351, 0.49026649],\n",
       "       [0.49385906, 0.50614094],\n",
       "       [0.48684973, 0.51315027],\n",
       "       [0.48766506, 0.51233494],\n",
       "       [0.43407198, 0.56592802],\n",
       "       [0.49008202, 0.50991798],\n",
       "       [0.46813345, 0.53186655],\n",
       "       [0.47551431, 0.52448569],\n",
       "       [0.49999822, 0.50000178],\n",
       "       [0.48516637, 0.51483363],\n",
       "       [0.49341709, 0.50658291],\n",
       "       [0.48182656, 0.51817344],\n",
       "       [0.54155927, 0.45844073],\n",
       "       [0.47778471, 0.52221529],\n",
       "       [0.48526562, 0.51473438],\n",
       "       [0.48838419, 0.51161581],\n",
       "       [0.46677793, 0.53322207],\n",
       "       [0.46445704, 0.53554296],\n",
       "       [0.46978429, 0.53021571],\n",
       "       [0.49532936, 0.50467064],\n",
       "       [0.46697987, 0.53302013],\n",
       "       [0.49623834, 0.50376166],\n",
       "       [0.45555853, 0.54444147],\n",
       "       [0.51081742, 0.48918258],\n",
       "       [0.51132233, 0.48867767],\n",
       "       [0.44049163, 0.55950837],\n",
       "       [0.46350289, 0.53649711],\n",
       "       [0.49907661, 0.50092339],\n",
       "       [0.5117532 , 0.4882468 ],\n",
       "       [0.48562813, 0.51437187],\n",
       "       [0.48819683, 0.51180317],\n",
       "       [0.45666277, 0.54333723],\n",
       "       [0.48471578, 0.51528422],\n",
       "       [0.47609273, 0.52390727],\n",
       "       [0.50834219, 0.49165781],\n",
       "       [0.46710223, 0.53289777],\n",
       "       [0.48125824, 0.51874176],\n",
       "       [0.45514548, 0.54485452],\n",
       "       [0.51362973, 0.48637027],\n",
       "       [0.49608529, 0.50391471],\n",
       "       [0.44493332, 0.55506668],\n",
       "       [0.48699243, 0.51300757],\n",
       "       [0.4635767 , 0.5364233 ],\n",
       "       [0.4458724 , 0.5541276 ],\n",
       "       [0.4515481 , 0.5484519 ],\n",
       "       [0.49732655, 0.50267345],\n",
       "       [0.47091947, 0.52908053],\n",
       "       [0.48126748, 0.51873252],\n",
       "       [0.49849178, 0.50150822],\n",
       "       [0.47874683, 0.52125317],\n",
       "       [0.45239428, 0.54760572],\n",
       "       [0.49453158, 0.50546842],\n",
       "       [0.51804684, 0.48195316],\n",
       "       [0.47132743, 0.52867257],\n",
       "       [0.48707634, 0.51292366],\n",
       "       [0.5129923 , 0.4870077 ],\n",
       "       [0.47627754, 0.52372246],\n",
       "       [0.5003242 , 0.4996758 ],\n",
       "       [0.48137655, 0.51862345],\n",
       "       [0.48707637, 0.51292363],\n",
       "       [0.47571326, 0.52428674],\n",
       "       [0.56207298, 0.43792702],\n",
       "       [0.47209201, 0.52790799],\n",
       "       [0.48498074, 0.51501926],\n",
       "       [0.49865826, 0.50134174],\n",
       "       [0.50108871, 0.49891129],\n",
       "       [0.51666847, 0.48333153],\n",
       "       [0.47940552, 0.52059448],\n",
       "       [0.48944971, 0.51055029],\n",
       "       [0.50051107, 0.49948893],\n",
       "       [0.49498885, 0.50501115],\n",
       "       [0.48642406, 0.51357594],\n",
       "       [0.55971864, 0.44028136],\n",
       "       [0.60447541, 0.39552459]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYHVWd//H3JyFAQ5CwGUwEooJBFAETQBZHgiiIjiADCjIojog7jmIEhJ/gNoCo4z6joiKgBheIbBoVEhiRfQ2LUWQREkCWBBJoJSTf3x/nNKlc7u2u6r5bd39ez1NP31t17jmnlq5v1amqU4oIzMzMyhrT6QqYmdnw4sBhZmaVOHCYmVklDhxmZlaJA4eZmVXiwGFmZpU4cIxAkqZKulHSUklHSeqRdIGkxyX9XNKhkn5bIp9PSTq9TXUedFmSzpD0+SbUodRyafDb2yTtMdQ6DAeSlkl6cRvLO1zSH1qY/68lvavw/fOSHpH0oKTN8/yObVX5w5H8HEfnSHoH8HFga2ApcBPwhYgY0j+JpO8DT0TEx/L3w4CPALtGxDNDq/Wg6jMFuBsY14ryJZ0B3B8RJzQ7724ob7STdDhwRETs3oayNgP+DGwREX9vdXnDlc84OkTSx4GvAv8FTAQ2B74N7NeE7LcAbqv5/udOBA0rT9Ia3ZzfKLEF8GgzgsaIXv4R4aHNA7A+sAw4qJ80a5ECy6I8fBVYqzD9zaQzlCXAH4FX5vGXAiuAf+Qyfgo8DSzP398DHA78oZDXy4HfAY8BDwGfyuNPAs4upHt1LmsJcDOwR2HaPOBzwBWks6ffAhvnaX8DIpe/DNilzvw+WxYwJad/V/7tI8Dx/SyrM4DPF76/F7gzz8/5wKTCtDcAC4DHSYH6MtLRLMXlAgj4b+DvOe0twCuAI/OyfDrPywU5/T3AXvnzWOBTwF/zsrge2KxOvfvm8z15Pi8vsZxfBFye8/098K06y61KfocDd+X87gYOzeO3zMvm8bz8zyn8JoAtC9vymcDDwL3ACcCY4vIEvgQszvm/sZ/1uBlwbs7rUeCbteslf/8acB/wRF62rylM2wm4Lk97CPhKHr82cHbOdwlwLTCxsO0eAewF9AIr87o9o7BM1yjM7/eBB4CFwOeBsYV6XkHabh6jsE2OtKHjFRiNA7AP8EzfxtggzWeBq4DnA5vkf/zP5WmvIu3QdibtpN5F2nGtlafPI+8M8/eTWD0APPuPCKyX/wmOzv9c6wE71/4OmJz/6fYlnam+Pn/fpFDmX4GXAj35+yl52mr/fA3mt1hWX/rv5by2A/4JvKzBb8/o+ycF9iTt6F5FCr7fYNUOdGPSDuUAYA3go6QgUC9w7E3aKU0gBZGXAS+oLa9Qh3tYFThmAvOBqfm32wEb1al333yeCayb53Wg5XwlaUe8JrB7np/a5VYqv5zmCWBq/v0LgJfnzz8Fjs+/WRvYvVDvYuA4E/gVabuZQmrmeU9heS4nBfKxwAdIB0GqsyzGkoLaf+d6PVsmzw0c/w5slNfh0cCDwNqF5XNY/jweeHX+/D7gAmCdXNY04Hm1/y/AHqRmyNp11Bc4ZgPfyXV8PnAN8L5CPZ8hNQuvAfR0el/TqsFNVZ2xEfBI9N90dCjw2Yj4e0Q8DHwGOCxPey/wnYi4OiJWRMSPSDvWVw+iLm8GHoyIL0fEPyJiaURcXSfdvwMXR8TFEbEyIn5HOrLbt5DmhxHx54joBX4GbD+I+hR9JiJ6I+Jm0k5luxK/ORT4QUTcEBH/BI4DdsnXWfYFbouIc/Oy/zppp1PPctLOcGvSju6OiHigZL2PAE6IiAWR3BwRj/aT/qSIeDIvt4bLWdLmwI7ApyPi6UjXws4fbH457UrgFZJ6IuKBiOhr4lxOaraZlLeL51x3yxeM3w4cl7ebe4Avs2o7Bbg3Ir4XESuAH5GC08Q6dd4JmATMzHWvWyZARJwdEY9GxDMR8WXSAcLUQr23lLRxRCyLiKsK4zciBbwVEXF9RDxRL/9GJE0E3gj8Z67j30mB7uBCskUR8Y1ct94q+Q8nDhyd8Siw8QBtoJNIp/597s3jIP1DHy1pSd9AOs2fRHWbkc4UBrIFcFBNmbuTdgR9ijvhp0hHfEMxmPxWW24RsYy0vCfnafcVpgVwf71MIuJS4JukpqCHJH1X0vNK1rvsMu1zX+Fzf8t5EvBYRDzV4LeV8ouIJ0k7/vcDD0i6SNLW+XefJJ0tXZPvGPuPOuVsTDrzqd1OJxe+P7sOC/Wutx43IwWZAa/DSTpa0h35LsElpOajjfPk95DOev8k6VpJb87jzwLmALMkLZL0RUnjBiqrxhbAONKy6luW3yGdefSptz5GHAeOzriSdA1i/37SLCJtqH02z+MgbZxfiIgJhWGdiPjpIOpyH/CSkunOqilz3Yg4pcRv23nr3mrLTdK6pCPNhaQmuRcWpqn4vVZEfD0ippGuAb2U1AQFA89P2WX6bFE1v220nB8ANpS0TiH9ZkPIj4iYExGvJwWmP5GaB4mIByPivRExidTM821JW9aU8wirzkz6bE5a1lXdB2w+0AVlSa8BjgHeBmwQERNI12GU6/2XiDiEtDM/FfiFpHUjYnlEfCYitgF2JZ1pv3MQdfwn6dpd37J8XkS8vJBmVNym6sDRARHxOPBp4FuS9pe0jqRxkt4o6Ys52U+BEyRtImnjnP7sPO17wPsl7axkXUlvkrTeIKpzIbCppP+UtJak9STtXCfd2cC/Stpb0lhJa0vaQ1LDHW/Bw6QmkXbc+/8T4N2Stpe0FumutatzM8pFwLZ5ma8BfAjYtF4mknbMy3cc8CQp0K/Ikx+i/3k5HficpK3y+nmlpI1K1r/hco6Ie0nNTCdJWlPSLsC/DjY/SRMlvSUH13+SLgivyPN/UGHdLibtEFcUM87NTz8DvpC3my1It5efTXXXkALjKXl7XlvSbnXSrUe6jvAwsIakTwPPnglK+ndJm0TEStJFcIAVkmZI2jY3rz1BCngrqCA3Vf4W+LKk50kaI+klkl5bdWaHOweODomIr5D+yU4g/RPcB3yYdPEN0t0a15Hu5pkP3JDHERHXka5zfJP0T30n6cLcYOqxlHTB9F9JzQp/AWbUSXcf6VbhTxXqO5MS21BuovgCcEU+xR/MtZhSIuIS4P8BvyTtiF5CboOOiEeAg4AvkpqvtiEt43/Wyep5pAC9mNT88ijpojSku2q2yfMyu85vv0Laof6WtJP6PulCdZn6D7ScDwV2yfX5PHBOg/qXyW8M6eLyItJdQK8FPph/uiNwtaRlpOsoH42Iu+sU8RFSYL2LdAfVT4AflJnXmnquIG2DW5LuCLuf1IxWaw7wa9JF+HtJAb3YPLQPcFuu99eAgyPiH6QDhF+Q1scdpDvGBhPg3klqnrudtG38gtWba0cFPwBoo5akMaQd1KERMbfT9RkMSecAf4qIEztdFxs9fMZho0puspmQm7E+RWobv2qAn3WN3IT2ktxMsg/pbKLeWY9Zy4zcJxvN6tuF1JzS19yw/zC7bXJT0kNyG5HOlj4QETd2tko22ripyszMKnFTlZmZVeLAMUJJukfSXp2uRyeoxd1wd7tuXfeSTpI0mDuZrMs4cNhzdOuOZzjJO8nlSu9y6Bva9g6LVpA0T9IRna7HUCi9u+XpmvXid21U5MBh1jrnRMT4wnBXpytkAHyxZr1UehDQHDhGuh0l3S5psaQfSlq7b4KkN0u6KT/E9kdJr8zjzyJ1G3FBPhr7pKQfSTo6T58sKSR9MH/fUtJjktRfvnnaJEm/lPSwpLslHVWYdpKkn0k6U+nNhbdJmt5oxnIdjpJ0l9Lb2k7Lz2UU03wpz/vdkt5YGP9upb6Olubfv68wbWNJF+b6Pybp//ry7a/+QyFpg1zmw7m+Fxae2u470v+cpCtynX+r1JtA3/TDJN0r6VFJxw9Q1hmSvqXUL9VSSVdLeklh+q5KfTw9nv/umsd/AXgN8M28XXyzTt5T8no5Uqk/qAf6tpuCNRutY0nHSvprnna7pLcWpm0p6bJcr0eUnl/pm7a1pN/l9bVA0ttKLXgbvOiCLno9NH8gdfN9K6kvow1J7wno63p8oG7Z7yF3EZ6//wer3jvxDlIHfucUpv1qoHxJBynXk7pOWZPUZcddwN75tyeRngLeN//2ZOCqfuYvgLl53jYnPUlc7B69YXfewJtIT5SL9LT0U8Cr8rSTgf8ldWY3jrSz1ED1r1O/k0h9KD1GeqnWB/qZl42AfyN1+b0e8HNgdmH6PBp3Wb8NqauQf8nL+SukLjn2alDWGblOO5Fux/8xMCtP25D0NPRhedoh+ftGhXoc0c98TMnr5aekbse3JT2tvldhmTRcx6Sn+iflZf120hPpfV3Z1+3mPZdzH/DuXOdXkfrQevkA8/9YXp//1un/1eE4dLwCHlq0YtMO+/2F7/sCf82f/4f8bo/C9AXAawu/LQaOl5D6/RlD2qm+j/zOAlJX2R8fKF9SMPlbzbTjSF2x9+1Ufl+Ytg3Q28/8BbBP4fsHgUvy58OBOwvT1snpN22Q12xSlxqQ3oPyK/L7Jgpp+q1/nTy3yTvBsaRO9R4ADim57rYHFhe+zyN1016c19/kz58m7/jz93VJL5nqL3CcXrNd/Cl/Pgy4pib9lcDhhXqUCRxbF8Z9Efj+INfxTcB++fOZwHeBF9akeTvwfzXjvgOc2CDPV7HqXR77kl5gtVsz//dGw+CmqpGt2IfPoLtlj4i/ko5qtycdgV8ILJI0lRQULiuR7xbApJppn2L1dzPUdqO+tvrvLbXR/K2WV9R0563UmeRVuWljCWkH0tf0cxqp76/f5masYwvzNlD9nxURt0fEokjvfvgjqd+kA+ulVerk8ju5uekJ0hv+Jmj1i7aNupiv7Sr+SVI/Vv3pL697a9LWdpNeRqn1Qs06lvTOQjPnEtIbF/vWS6Nu3rcAdq5ZL4fSoPPKSO9p6XuXx8WkM64DKs7fqOcnx0e2Ypfb9bpl/0KD39V7KvQy0o5vzYhYKOkyUodvG5CODPvNV6kn17sjYqvqs9HQZqx6t3px/hpS6mrkl6S6/yoilit1VNjXLfdSUsd/R0t6OTBX0rWkeRtK/aOvjDqOJr2IaOeIeFDS9sCN/aQveoD0dkIgBSHSEfVg1HblD2m5/iZ/Lvu08GakLtr7fl9mvWxB6lTydcCVEbFC0k2sWi8PkpoekbQ78HtJl5PWy2WRuoYfjP7WizXgM46R7UNK3WdvSDo67rugOFC37PW6Db+M1Hvv5fn7PFLPqH+IVXel9JfvNcATko6R1KPUxfcrJO04hPmbmS8sb0Z6Dew5A/2AdH1iLVLb+zNKF83f0DdR6eL+lpJE6kl1RR4q1V/SfrlukrQTcBSpCaye9Ujvul6S11WVDgt/AbxZ0u6S1iQ1tQ32//pi4KWS3iFpDUlvJzUnXZinD9SdfJ//l8+iXk669lBmvaxL2ok/DOkGBtIZB/l7o27eL8x1Pkzp1QTjlPrzehl1SDpQ0nilvr7eQHpDYr23KFo/HDhGtp+Quva+Kw9lu2U/mfQukCWSPpHHXUbawfUFjj+Qrh30fe8331jVbfb2wN2kC5ink97eNli/Il3gvIn0ro3vD/SDfEZxFKnb88Wki/3FHcdWwO9JTXNXAt+OiHmDqP/BpPlfSmqfPzXSK37r+SrpovcjpA4Xf9MgXb35uY30XpGfkM4+FtPgrYYl8nqU9IKjo0nNXZ8E3hypO3rIzW1Kd359vZ+sLiPN+yXAlyLityXKvp302tkrSQFqW9INHX3qdvOe1+cbSMt7Eakp7FTSwUE9HyW9aGoJqVnyvRExb6D62ercV5UNS5IC2Coi7ux0XSxReq/73cC4KPEKWBu+fMZhZmaVOHCYmVklbqoyM7NKfMZhZmaVOHCYmVklI/IBwI033jimTJkyqN8++eSTrLvuum1P57Jddrelc9mjq+zrr7/+kYjYpFQlO93nSSuGadOmxWDNnTu3I+lctsvutnQue3SVDVwX7qvKzMxawYHDzMwqceAwM7NKHDjMzKwSBw4zM6vEgcOszWbfuJDdTrmU+QsfZ7dTLmX2jQs7XSWzSkbkcxxm3Wr2jQs57tz59C5fAZvBwiW9HHfufAD236Hqi/bMOsNnHGZtdNqcBSloFPQuX8FpcxZ0qEZm1TlwmLXRoiW9lcabdSMHDrM2mjShp9J4s27kwGHWRjP3nkrPuLGrjesZN5aZe0/tUI3MqvPFcbM26rsAnq5pLGXyhB5m7j3VF8ZtWOnoGYekH0j6u6RbG0yXpK9LulPSLZJe1e46mjXb/jtM5opj92TbyetzxbF7OmjYsNPppqozgH36mf5GYKs8HAn8TxvqZGZm/eho4IiIy4HH+kmyH3Bm7vX3KmCCpBe0p3ZmZlZPp884BjIZuK/w/f48zszMOkTp/R0drIA0BbgwIl5RZ9pFwMkR8Yf8/RLgkxFxfZ20R5Kas5g4ceK0WbNmDao+y5YtY/z48W1P57Jddrelc9mjq+wZM2ZcHxHTS1Wy7BufWjUAU4BbG0z7DnBI4fsC4AUD5ek3ALpslz30dC57dJXNCHoD4PnAO/PdVa8GHo+IBzpdKTOz0ayjz3FI+imwB7CxpPuBE4FxABHxv8DFwL7AncBTwLs7U1MzM+vT0cAREYcMMD2AD7WpOmZmVkK3N1WZmVmXceAwM7NKHDjMzKwSBw4zM6vEgcPMzCpx4DAzs0ocOMzMrBIHDjMzq8SBw8zMKnHgMDOzShw4zMysEgcOMzOrxIHDzMwqceAwM7NKHDjMzKwSBw4zM6vEgcPMzCpx4DAzs0ocOMzMrBIHDjMzq8SBw8zMKnHgMDOzShw4zMysEgcOM7Ns9o0L2e2US5m/8HF2O+VSZt+4sNNV6kprdLoCNjrMvnEhp81ZwKIlvUya0MPMvaey/w6TO10ts2fNvnEhx507n97lK2AzWLikl+POnQ/gbbVGR884JO0jaYGkOyUdW2f64ZIelnRTHo7oRD1taPr+IRcu6SVY9Q/poznrJqfNWZCCRkHv8hWcNmdBh2rUvToWOCSNBb4FvBHYBjhE0jZ1kp4TEdvn4fS2VtKawv+Q1kllm58WLemtNH406+QZx07AnRFxV0Q8DcwC9utgfaxF/A9pnVI824X+z3YnTeipm0ej8aOZIqIzBUsHAvtExBH5+2HAzhHx4UKaw4GTgYeBPwMfi4j7GuR3JHAkwMSJE6fNmjVrUPVatmwZ48ePb3u6kVz2ggeX8vSKlc9Js+bYMUzddL0RO9/dWvZwqGOz8ixuexN74KF8rNK37RUt6V3OwsW9rIx4Nu0Yickb9DChZ1zL6tjqPMummzFjxvURMb1UJSOiIwNwEHB64fthwDdq0mwErJU/vx+4tEze06ZNi8GaO3duR9J1U9nn3XB/7HryJTHlmAtj15MvifNuuH9IZZ93w/2x9Qm/ji2OufDZYesTfv1svt0y36Ol7OFQx2blOaWwzX397NnPfp5yzIV10/dt+18/e/Zztv1W1bHVeZZNB1wXJfffnbyr6n5gs8L3FwKLigki4tHC1+8Bp7ahXqPaaneW0Jw7S/p+57uqrN0mTeh5tpmqdnw9++8wmf13mMy8efP4yKF7tLh2w1cnA8e1wFaSXgQsBA4G3lFMIOkFEfFA/voW4I72VnH06e9C9lB29H3/kGbtNHPvqasdCAH0jBvLzL2ndrBWw1/HAkdEPCPpw8AcYCzwg4i4TdJnSadM5wNHSXoL8AzwGHB4p+o7WvhCto0kxbNdWMrkLjjbHQnPNHX0AcCIuBi4uGbcpwufjwOOa3e9RrOqp/Zm3a6bmp9a0RTcCe5yxFYzc++p9Iwbu9o4n9qbNcdIeabJXY7Yanwh26x1RkpTsAOHPYcvZJu1xkhpCnZTlZlZm4yUpmCfcZiZtclIaQp24DAza6OR0BTspiozM6vEgcPMzCpx4DAzs0ocOMzMKhrt7yb3xfF+jIQ+ZYYbL3Prdn43uc84GvJ7stvPy9yGg5HSbchQOHA04I2j/bzMR66R1LQzUroNGQoHjga8cbSfl/nIVOW938OB303uwNGQN4728zJvrU4d9Y+0M8mR0m3IUDhwNOCNo/2GyzLv2wG/6NiLhk2zSyeP+kfameT+O0zm5AO2ZXI+oJk8oYeTD9i2bRfGu6HZz3dVNTBS+pQZTobDMh+uL+Jp1SuByxgpPcIWderlUN1yR5cDRz9GQp8yw023L/NO7oAb6buF+eDNlnL8KZfWDbadPOrv1vd+N/vW73bcSt4t258Dh1kF3dbsUvYItJ1H/fV2oCcfsG3Xvfe7mWeO7ToT7Zbtz9c4rGO6oa22Xn36u3bRqgv49cous3zKXnju7/pRM6/ZNHoWB+CKY/dk28nrc8Wxe3b8rLLZF+zbdQNAo+1s/Z5xbb3u5sBhHdFtt2iWffiwFRfw65U98+c3M/MXNw+4fMoegTa6oAs09aHL4XIHVbOP3Nt1JlBv+xs3Rjz59DNtfXDWgcOaquxZRKd3MLX1/MwFt5WqT3EHLJpzR029ZbF8ZbB8RQxYnypnQPvvMPk5R/3NXg/N2IG240y02WeO7bqVvN4BwPi11yi1rTSTA4cNWm0Txwmz55c+i+hkW229s53FTy0vXZ++HfDdp7ypKc0uVea5Nu1Qz4CGuh5qd/IT1hlXN13ZHWi7zkSbfebYKL8ZW2/S9CBYewCwpMK22ywOHFkn29ubXXYr5qU2z2KQ6Ds9/vFVfyt99NrJh/3qHWU3UmWHN9hlXmWea9MO9ZmCoayHejv5Zf94hnFjtVq6KjvkoZ4Blb1eU+XMsUye9fL7t2mT+eX1C1seBDvxv+S7qujsvdHNLrsV81Ivzx9f9TeiJl3t9z71jnw6eYtm2SOxsvUZ6jKvtyzGjRGI1ZogGtVnKM8UDGU9NGpim9AzjnXXWmNQt6UO5Qyo6p1NZW79rpJnbX67nXJpW26d7cT/UkcDh6R9gK8BY4HTI+KUmulrAWcC04BHgbdHxD3Nrkcn741udtmtmJd6eTYKEvU0am/vy3swt2gO5Z75RremDnaHN9Rl3ujBx75xrVw+Q3nostHO/PHe5dx04htK1bPWUG4bbte2XzbPdjXHduLB2Y4FDkljgW8BrwfuB66VdH5E3F5I9h5gcURsKelg4FTg7c2uSyfb24fD3R1VfitWDyr9HfkM9kh5qPfMNzpCO+ktLx/UP1szlnmjo992LJ/BPnTZimdDqhw91z74WK8u0Jptv0ye7Xx2pt0Pzpa6xiHp1DLjKtoJuDMi7oqIp4FZwH41afYDfpQ//wJ4nSTRZJ1sbx8Od3c0+m3tiugZN5ZDX715y/vwaXQUeNL5t5W6ztDsvoa6rXPGdt2x1opbk8uum3rXVxrtGFqx7ZfJc7j0vTYYihi40UHSDRHxqppxt0TEKwddsHQgsE9EHJG/HwbsHBEfLqS5Nae5P3//a07zSJ38jgSOBJg4ceK0WbNmla7Lkt7lLFzcy8oIJvbAQ70wRmLyBj1M6Kl/l8iyZcsYP378gHkPlK7ZZfeXH8BDj/+Dp1esZM2xY5i4/trPjttgzZUsfjqNqy23UZ4brDOOpf94ZrX8+n5bdvlUSduXbv7Cx/tNV3Y5DqbsegazDptVdr10/S2fbSev39R1s6R3+YDbT5X8yqZd8OBSnl6xEli1vusprofBlF1ct4PJs+ryKZZd/P1Q/sfKppsxY8b1ETF9wIQM0FQl6QPAB4EXS7qlMGk94IoyBfSXfZ1xtVGsTJo0MuK7wHcBpk+fHnvssUelyhRPe2fdt17DNsJV6VYw69aVA7Ylzps3j4HqUq9sgOMbtFkOlGej/FITwBj6TjTHjVmeL8CO4ehtV/Ll+WPoGbeCkw/Ypu4RXpnlU2W+q6btS9dfswTA0ds+w5fnp0178oSxXHFs47yrlt1I1eXTzLJr0zVaPpMn9PCRQ/do2bp5WxPnZaC07z72IiJvx8X1DWk+B/N/06js/q4XNXv5FPOcfeNCjrtk9f/Z4v9ns7efKga6xvET4NfAycCxhfFLI+KxIZZ9P7BZ4fsLgUUN0twvaQ1gfWCo5dZVpr29VXdf1ZbdqI36unsfY+6fHu63M7tG81LvDo/lK58bgxtd+OtUb6D11GsHb2Thkl52O+XSll807PblU7WJpEzHie1Uu/OesM64us/eTJ7QwxXH7tnUsjvV8Wa3dGhYT7/XOCLi8Yi4JyIOIe3El5OO+MdL2nyIZV8LbCXpRZLWBA4Gzq9Jcz7wrvz5QODSKNO21iLtajtuVM6Pr/rboO8JH8pDZt2m3j3zGzR48Eww6t5hPtSn24dDdzBDfV6kG9U+C9SKi/3NUuquKkkfBk4CHgJW5tEBDPoaR0Q8k/OdQ7od9wcRcZukzwLXRcT5wPeBsyTdSTrTOHiw5TVDu+6+apRfbcSscvTR6A6PRmm7Xe1RYO1ZGjz3Di/oniO2VhvKUXK3HekO9LxIt/S4OxT1WjPqbb/QHf+fZZ8c/09gakS8PCK2zcOgg0afiLg4Il4aES+JiC/kcZ/OQYOI+EdEHBQRW0bEThFx11DLHIoqd1i060niskGrUedoI+Word7dOFUeSLRVuqXr7oHKfbx3eVf1uDsUjZ6VqnfnYjf8f5YNHPcB/d/KMgqUvb1uqKf69coZ6q2G9ZovTjtoO047cLuOvQKz2Wr78Jk8hFspR7Nuu7242+rTCv21MjSzQ81mKfsA4F3APEkXAf/sGxkRX2lJrbpU2aedW/Ek8YytN+GX1y8c0gXPZj5kNhx065vnul23Lbduq08rNGpKbsXF/mYoGzj+loc18zBqlbl7plVPEk/fYsOueotauwz2Dp9OdMUwEgy1O5hW1mekrsfhFhxLBY6I+AyApHUj4snWVmn4a1VXA910y2e7DPUW6E7dSjncddu2NtLXY7cF64GU7XJkF0m3A3fk79tJ+nZLazaMjeSuBtqt0y98MmuX2mt03Ro0oHxT1VeBvcnPWUTEzZL+pWW1GuaG29FDN+u2O3zMrELvuBFxX03/guXehDNKNTrVH0p34KNRO3sYNbNySt+OK2lXICStKekT5GYrK6/eE7D8z72fAAAUGUlEQVSj4UnmoXCzn1n3KRs43g98CJhM6npk+/zdKnB7fXXN7gLdzIau7F1VjwCHtrguI57b6wen2+7wMRvtBupW/ZMR8UVJ36BOtykRcVTLajYCub3ezEaCgc44+q5jXNfqiowGw+0hHzOzevoNHBFxQf77o/7SWTmj4QlYMxv5ynar/jvgoIhYkr9vAMyKiL1bWbmRqNlPwPr2XjNrt7LPcWzSFzQAImKxpOe3qE7DTqd23o3eFAhDeyOhWT0+SLE+ZW/HXVF845+kLWjw7u/RppPPZvj2XmsXP4NkRWUDx/HAHySdJeks4HLguNZVa/jo5M7bt/dau/ggxYrKPsfxG0mvAl5NeqfQx/KzHaNeJ3fevr3X2sUHKVbU7xmHpK3z31cBmwOLgIXA5nncqNfJt5O5Ow5rl9HwFj4rb6Cmqo/nv1+uM3yphfUaNjq58673Olh3x2Gt4IMUKxqoqep3+e97IuKuVldmOOr0sxkj/QU31h06vZ1bdxkocBwH/Bz4BeCmqQa887bRwNu59RkocDwmaS7wYknn106MiLe0plpmZtatBgoc+5LONM4iXdcws5L8wJyNVAMFju9HxGGSvhcRlzWrUEkbAucAU4B7gLdFxOI66VYA8/PXv/kMx4YLP9VvI9lAd1VNy0+JHyppA0kbFochlHsscElEbAVckr/X0xsR2+fBQcOGDT8wZyPZQGcc/wv8BngxcD3p4b8+kccPxn7AHvnzj4B5wDGDzMus6/iBORvJ+j3jiIivR8TLgB9ExIsj4kWFYbBBA2BiRDyQy3gAaNRh4tqSrpN0laT9h1CeWVv5gTkbyRRRrq9CSbsDW0XEDyVtDKwXEXf3k/73wKZ1Jh0P/CgiJhTSLo6IDerkMSkiFkl6MXAp8LqI+GuD8o4EjgSYOHHitFmzZpWar1rLli1j/PjxbU/nsruz7CW9y3no8X+wwZorWfz0GCauvzYTesYNmN+S3uUsXNzLysL/1xiJyRv0PPv7Ts33SFk3Lru56WbMmHF9REwvVcmIGHAATgQuAP6cv08Crijz2wb5LQBekD+/AFhQ4jdnAAeWyX/atGkxWHPnzu1IOpfdfWWfd8P9sfUJv44tjrkwvn727NjimAtj6xN+HefdcH+p/M674f7Y9eRLYsoxF8auJ1/ynN91ar5Hwrpx2c1PB1wXJffhZd/H8VZgB+CGHGwWSVqv5G/rOR94F3BK/vur2gT5ZVFPRcQ/8xnObsAXh1CmWSX9XeAuc2eUH5izkapst+pP54gUAJLWHWK5pwCvl/QX4PX5O5KmSzo9p3kZcJ2km4G5wCkRcfsQyzUrzRe4zeore8bxM0nfASZIei/wH8D3BltoRDwKvK7O+OuAI/LnPwLbDrYMs6Fyt/Vm9ZU644iIL5H6q/olMBX4dER8o5UVM+s09whrVl/ZMw6AW4C18uebW1AXs65S7BEWljLZ3YaYASXPOCS9DbgGOAh4G3C1pANbWTGzbrD/DpO54tg92Xby+lxx7J4OGmaUP+M4HtgxIv4OIGkT4Pek5iszMxtFyt5VNaYvaGSPVvitmZmNIGXPOH4jaQ7w0/z97cDFramSmZl1s34Dh6QtSf1KzZR0ALA7qaPDK4Eft6F+ZmbWZQZqbvoqsBQgIs6NiI9HxMdIZxtfbXXlzMys+wwUOKZExC21I/ODelNaUiMzM+tqAwWOtfuZ5sdnzcxGoYECx7W5i5HVSHoP6cVOZmY2ygx0V9V/AudJOpRVgWI6sCapx1wzMxtl+g0cEfEQsKukGcAr8uiLIuLSltfMzMy6UqnnOCJiLqlrczMzG+X89LeZmVXiwGFmZpU4cJiZWSUOHGZmVokDh5mZVeLAYWZmlThwmJlZJQ4cZmZWiQOHmZlV4sBhZmaVOHCYmVklHQkckg6SdJuklZKm95NuH0kLJN0p6dh21tHMzOrr1BnHrcABwOWNEkgaC3wLeCOwDXCIpG3aUz0zM2ukVO+4zRYRdwBI6i/ZTsCdEXFXTjsL2A+4veUVNDOzhhQRnStcmgd8Ir/DvHbagcA+EXFE/n4YsHNEfLhBXkcCRwJMnDhx2qxZswZVp2XLljF+/Pi2p3PZLrvb0rns0VX2jBkzro+IhpcOVhMRLRmA35OapGqH/Qpp5gHTG/z+IOD0wvfDgG+UKXvatGkxWHPnzu1IOpftsrstncseXWUD10XJ/XvLmqoiYq8hZnE/sFnh+wuBRUPM08zMhqibb8e9FthK0oskrQkcDJzf4TqZmY16nbod962S7gd2AS6SNCePnyTpYoCIeAb4MDAHuAP4WUTc1on6mpnZKp26q+o84Lw64xcB+xa+Xwxc3MaqmZnZALq5qcrMzLqQA4eZmVXiwGFmZpU4cJiZWSUOHGZmVokDh5mZVeLAYWZmlThwmJlZJQ4cZmZWiQOHmZlV4sBhZmaVOHCYmVklDhxmZlaJA4eZmVXSkW7VzcwAZt+4kNPmLGDRkl4mTehh5t5T2X+HyZ2ulg3AgcPMOmL2jQs57tz59C5fAcDCJb0cd+58AAePLuemKjPriNPmLHg2aPTpXb6C0+Ys6FCNrCwHDjPriEVLeiuNt+7hwGFmHTFpQk+l8dY9HDjMrCNm7j2VnnFjVxvXM24sM/ee2qEaWVm+OG5mHdF3Adx3VQ0/Dhxm1jH77zDZgWIYclOVmZlV4sBhZmaVOHCYmVklHQkckg6SdJuklZKm95PuHknzJd0k6bp21tHMzOrr1MXxW4EDgO+USDsjIh5pcX3MzKykjgSOiLgDQFInijczsyFQRHSucGke8ImIqNsMJeluYDEQwHci4rv95HUkcCTAxIkTp82aNWtQdVq2bBnjx49vezqX7bK7LZ3LHl1lz5gx4/qIaHjpYDUR0ZIB+D2pSap22K+QZh4wvZ88JuW/zwduBv6lTNnTpk2LwZo7d25H0rlsl91t6Vz26CobuC5K7t9b1lQVEXs1IY9F+e/fJZ0H7ARcPtR8zcxs8Lr2dlxJ60par+8z8AbSGYuZmXVQp27Hfauk+4FdgIskzcnjJ0m6OCebCPxB0s3ANcBFEfGbTtTXzMxW6dRdVecB59UZvwjYN3++C9iuzVUzM7MBdG1TlZmZdScHDjMzq8SBw8zMKnHgMDOzShw4zMysEgcOMzOrxIHDzMwqceAwM7NKHDjMzKwSBw4zM6vEgcPMzCrp1KtjzWwQZt+4kNPmLGDRkl4mTehh5t5T2X+HyZ2ulo0yDhxmw8TsGxdy3Lnz6V2+AoCFS3o57tz5AA4e1lZuqjIbJk6bs+DZoNGnd/kKTpuzoEM1stHKgcNsmFi0pLfSeLNWceAwGyYmTeipNN6sVRw4zIaJmXtPpWfc2NXG9Ywby8y9p3aoRjZa+eK42TDRdwHcd1VZpzlwmA0j++8w2YHCOs5NVWZmVokDh5mZVeLAYWZmlThwmJlZJQ4cZmZWiQOHmZlVoojodB2aTtLDwL2D/PnGwCMdSOeyXXa3pXPZo6vsLSJikxLpICI8FAbguk6kc9kuu9vSuezRV3bZwU1VZmZWiQOHmZlV4sDxXN/tUDqX7bK7LZ3LHn1llzIiL46bmVnr+IzDzMwqceAwM7NKHDjMzKySUR04JG0t6RhJX5f0tfz5Zf2kfZ2k8TXj9xmgjDMbjN9Z0vPy5x5Jn5F0gaRTJa1fSLempHdK2it/f4ekb0r6kKRxVefZVpH0/AppN2plXWxkK7utDZftbNQGDknHALMAAdcA1+bPP5V0bE3ao4BfAR8BbpW0X2HyfxXSnV8zXAAc0Pe9pgo/AJ7Kn78GrA+cmsf9sJDuh8CbgI9KOgs4CLga2BE4fdALYJDa9Q8gaX1Jp0j6k6RH83BHHjehkO55kk6WdJakd9Tk8e3C5w1rho2AayRtIGnDmt+dImnj/Hm6pLuAqyXdK+m1hXTTJc2VdLakzST9TtLjkq6VtEMh3RqS3ifpN5JukXSzpF9Len9t8Jc0Nqf9nKTdaqadMMAy+3OdcR8uzMuWki6XtETS1ZK2rUn7Ykk/kPR5SeMlfU/SrZJ+LmlK1flp9rxUmZ+y85LTdmRbK7udFaaX2dZKzcuQNfuJwuEyAH8GxtUZvybwl5px84Hx+fMU4Drgo/n7jYV0NwBnA3sAr81/H8ifX1uT5x3F39VMu6nw+Zb8dw3gIWBs/q6+aYW06wOnAH8CHs3DHXnchEK65wEnA2cB76jJ49uFzxvWDBsB9wAbABsW0p0CbJw/TwfuAu4kdftSO9/Tgbl5OW0G/A54nBS4dyikmwMcA2xaGLdpHve7wrhf5vL3B87P39eqXa7ASuDummF5/ntX7foufJ4L7Jg/v5TCU7ikA443AocA9wEH5vGvA64spPsp8D/Aq4EX5uHVedw5NWWfDvwE+E/geuAr9bYTYCnwRB6W5mFF3/hCutsKny8C3po/7wFcUVP25cAHgGOBW4Gj8zp6D3Bp1flp9rxUmZ+y89LJbY2S21nFba3UvAx16PgOvFMDaee6RZ3xWwALasbdXvN9PPAb4CusvpMfA3yMtDPcPo+7q0H5PwfenT//EJhe2GiuLaS7lRTMNsj/SBvm8WtTCD4j8B9gQb3lVjutuPzz9+OBK0hBrjgvn8jrbNvCuLv72TbWyJ+vqplWnNfiQcPfatLdWK++dcr6c833Wwqf1yDdg38usFZNnt8AzgQm9jc/Ncvq2kZltWJ+mj0vVean7Lx0clsru501cd00nFZ1aEomw3EA9iEdFf86b9DfzSv7TmCfmrSXkgNBYdwaeWNfUSfvF5ICwzdrV3IhzfrAGcBfSU1Py0lH6pcB2xXSfSyPvxc4CrgE+B7pLOjEshvGMPwH+C3wyZqdyURSEPx9YdwdwJiafN4F3Abc22C9fAVYj8ZB/SO5/D2Bk4CvAv8CfAY4q5DuSuANpObDe4H98/jXsvqZyVU5zZjCuDHA24Gra5dlnfqcmNdP7ZnwtLxtHpXze878AF/I29mLgU+Rjv43B94NXFiT9npSsN+J1Cle38HMlqy+Uy41P82elyrzU5iXHfubl05ua2W3s4rbWql5GerQ0p1ztw95A3018G/Agfnz2DrpXkjhKL5m2m795P8m4L8GqMN6wHb5H2digzSTgEn584Rc153qpBtJ/wAbkK75/AlYDDyW630qqzeTfRHYq06d9qFm51SY9q+knd+D/ayXPYBzgBtJQfpi4EgKzZt5vc0hHXxsTbpWtSQvx10L6abkvP5OaiL9c/58DvCimnLPpubAJY8/AljeYBs+Cvg/YFGDeTmcdHDyCOms9XbStbn1a9K9DliQl/PupDPRv+S67ldnfh7O89KXZrX5acW85HTvHmh+BpiX/Wvy69i2VmY7y+m2r7OtLc7b2m5V52WoQ1My8dAdQ81G81jNRrNBIV07/wHWqElXameb024N7EW+vlSsZ510r6uT7o2N0gE9wCvq5TdAnrVlv6xkup1JR/Ib5R3ZJ4B9GyzLnVjV3LcN8PF6aWvSvQb4dIl0Lye19zcqe+eatA3rmdNsROq2++yS2+iZJdK8AHi0wnZ/Vsl0F1JzwNQg3WvyMnrDAOl2z+tmoHSvAU4omW7AcvtLm9ff+vnzOsBn83yfSs2BwlCGpmTiofsH8vWUoaSr2dkOOb/+0pKOPBcAs0kX5ItHvMXmtI+UTFcqv4plH0UK0gOlO5EUdK8j3ZRwSd7JXw4cX1N2bdpL66Utm+cQy26U5/l1hmV9n/tJd0HJdHXzG2LZ/eV5TeHzEaSDnxNJTWrHNkj3XuCmkunK5New3Ip53saqZuPvAv9NCnAnAuc2bX/SrIw8dPdAg2st3ZKuNi3l72RraroWlj2WdAT4BPC8PL6H57a3l0rb7HQV8yx19yBp51YmXZW7EZtadp11dS2wSf68Lo1vhmhbuop5lrpbc6jDGtiIIemWRpNI1zo6mq5i2rERsQwgIu6RtAfwC0lb5LStSteKPJ+JiBXAU5L+GhFP5N/0SlpZU3bZtM1OVyXtdOCjpJsqZkbETZJ6I+KymvymlUxXNr9WlA0wRtIGpGssioiH83w/KemZLkhXJe2tkt4dET8EbpY0PSKuk/RS0g04TeHAMbJMBPYmXRQrEvDHLkhXJe2DkraPiJsAImKZpDeTHpzctoXpWpHn05LWiYinSDu0NMOph4DanXfZtM1OVzptRKwE/lvSz/Pfh6izL2l2ulblSbrD8XrSNhiSNo2IB5V6iVAXpKuS9gjga0oPWD4CXCnpPtKt70c0mP/qmnXq4qHzA/B9YPcG037S6XQV8yx1J1uz07Wo7LUapNmYwq3OVdI2O13VtDXTB7x7sBXpWpVn4TfrUHPXWzel6y8tJe7WHMrg93GYmVklo7avKjMzGxwHDjMzq8SBw2yQJG0k6aY8PChpYeH7mhXz+qGkqa2qq1kz+RqHWRNIOglYFhFf6nRdzFrNZxxmLSDpk0rvf7hV0kfyuC0l3ab0Pof5kn4mqSdP+4Ok7fPnN0m6Qek9F7/t5HyY1ePAYdZkknYCDiX1EbUL8EFJr8yTtwG+FRHbAv8A3lfz201J77V4a0RsBxzctoqbleTAYdZ8rwF+GRFPRcRSUl9Wu+dpd0fEVfnz2YXxfXYB5kbEvQAR8Vg7KmxWhQOHWfPVPvVbVHtRsfa76owz6yoOHGbNdznwVkk9uUuI/UjvmAB4kaQd8+dDgD/U/PYKYM/c3xWqeR+6WTdw4DBrsoi4hvRe7mtJ3ZT/T0TMz5NvA96bO3tcl9T1dfG3D5Helf0rSTcDP25bxc1K8u24Zm0iaUvgFxGxfafrYjYUPuMwM7NKfMZhZmaV+IzDzMwqceAwM7NKHDjMzKwSBw4zM6vEgcPMzCpx4DAzs0r+P/sOT767tGePAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(clf.coef_[0])),clf.coef_[0])\n",
    "plt.xticks(range(0,len(clf.coef_[0])+1,2),rotation=90)\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Coefficient in logistic regression classifier \\nbetween phase 5 and not phase 5')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shkvir', 0.08063437),\n",
       " ('kytk', 0.029709047),\n",
       " ('sarj', 0.018370252),\n",
       " ('lait', 0.017849041),\n",
       " ('komponent', 0.015947282),\n",
       " ('shkmoottor', 0.01339101),\n",
       " ('shklait', 0.012932554),\n",
       " ('eli', 0.0125470385),\n",
       " ('raken', 0.012349038),\n",
       " ('laite', 0.0113198925)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topic(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3111038067516104"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005360692171084533"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = get_topic_distribution(trainset)\n",
    "X_test,y_test = get_topic_distribution(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# make 3-class dataset for classification\n",
    "centers = [[-5, 0], [0, 1.5], [5, -1]]\n",
    "X, y = get_topic_distribution(trainset)#make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
    "#transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
    "#X = np.dot(X, transformation)\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1905"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_1 = pca.components_[0]\n",
    "v_2 = pca.components_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01142853, -0.00731208,  0.00909848, ..., -0.00595645,\n",
       "        -0.00731979,  0.01270913],\n",
       "       [ 0.00438504,  0.01574188, -0.00982099, ..., -0.00363591,\n",
       "        -0.0088206 , -0.01543635],\n",
       "       [-0.00066237,  0.00652247,  0.00300619, ..., -0.00666595,\n",
       "        -0.00543397,  0.0061896 ],\n",
       "       ...,\n",
       "       [ 0.04354618, -0.04109778, -0.11646606, ..., -0.0322638 ,\n",
       "        -0.01654347,  0.23272723],\n",
       "       [-0.02016083,  0.01519194,  0.06609278, ..., -0.03702898,\n",
       "         0.03868529, -0.34274174],\n",
       "       [-0.03794056, -0.12599665,  0.15772072, ...,  0.02085024,\n",
       "         0.05684396, -0.21580076]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2853bb1a51c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pca' is not defined"
     ]
    }
   ],
   "source": [
    "Xdot = np.dot(X,pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = {1:'r',2:'b',3:'g',4:'y',5:'black'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xdot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-87aefb6f61d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXdot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Xdot' is not defined"
     ]
    }
   ],
   "source": [
    "Xdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-428b458e5378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolor_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXdot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: scatter() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "color_label = [colors[i] for i in y]\n",
    "plt.scatter(Xdot,color=color_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dot = np.array(list(map(lambda x: np.dot(v_1,x),X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(X_dot,Y_dot,color=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 49]\n",
      " [ 0  0  0 27]\n",
      " [ 1  0  8 29]\n",
      " [ 0  0  3 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        49\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.73      0.21      0.33        38\n",
      "           5       0.40      0.96      0.56        72\n",
      "\n",
      "   micro avg       0.41      0.41      0.41       186\n",
      "   macro avg       0.28      0.29      0.22       186\n",
      "weighted avg       0.30      0.41      0.28       186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CATALINA ESPINOZA\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score : 0.415 (multinomial)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 60",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-158e1d764c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Plot the decision boundary. For that, we will assign a color to each\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# point in the mesh [x_min, x_max]x[y_min, y_max].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Put the result into a color plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 262\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features per sample; expecting 60"
     ]
    }
   ],
   "source": [
    "for multi_class in ('multinomial', 'ovr'):\n",
    "    clf = LogisticRegression(solver='sag', max_iter=100, random_state=42,\n",
    "                             multi_class=multi_class).fit(X, y)\n",
    "\n",
    "    # print the training scores\n",
    "    print(\"training score : %.3f (%s)\" % (clf.score(X, y), multi_class))\n",
    "\n",
    "    # create a mesh to plot in\n",
    "    h = .02  # step size in the mesh\n",
    "    X_dot = np.array(list(map(lambda x: np.dot(v_1,x),X)))\n",
    "    Y_dot = np.array(list(map(lambda x: np.dot(v_2,x),X)))\n",
    "    x_min, x_max = X_dot.min() - 1, X_dot.max() + 1\n",
    "    y_min, y_max = Y_dot.min() - 1, Y_dot.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "    plt.title(\"Decision surface of LogisticRegression (%s)\" % multi_class)\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Plot also the training points\n",
    "    colors = \"bry\"\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired,\n",
    "                    edgecolor='black', s=20)\n",
    "\n",
    "    # Plot the three one-against-all classifiers\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    coef = clf.coef_\n",
    "    intercept = clf.intercept_\n",
    "\n",
    "    def plot_hyperplane(c, color):\n",
    "        def line(x0):\n",
    "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
    "        plt.plot([xmin, xmax], [line(xmin), line(xmax)],\n",
    "                 ls=\"--\", color=color)\n",
    "\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        plot_hyperplane(i, color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
