{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier by layers\n",
    "\n",
    "This notebook trains a classifier that operates in two layers:\n",
    "- First we use a SVM classifier to label utterances with high degree of certainty.\n",
    "- Afterwards we use heuristics to complete the labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and path definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_path = os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "sys.path.append(root_path)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from src import phase_classification as pc\n",
    "\n",
    "data_path = os.path.join(root_path,'data')\n",
    "tables_path = os.path.join(data_path,'tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_STEMMING = True\n",
    "#REMOVE_STOPWORDS = True\n",
    "SEED = 10\n",
    "NUM_TOPICS = 60\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '[train]IBL_topic_distribution_by_utterance_minimum_5_words_with_stemming_{}_{}.xlsx'.format(WITH_STEMMING,NUM_TOPICS)\n",
    "df_data = pd.read_excel(os.path.join(tables_path,'train',file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "key 1, samples: 403, prop: 0.25\n",
      "key 2, samples: 175, prop: 0.11\n",
      "key 3, samples: 406, prop: 0.25\n",
      "key 4, samples: 62, prop: 0.04\n",
      "key 5, samples: 554, prop: 0.35\n"
     ]
    }
   ],
   "source": [
    "the_keys = list(set(df_data['phase']))\n",
    "total_samples = 0\n",
    "class_samples = {}\n",
    "for key in the_keys:\n",
    "    n = list(df_data.phase.values).count(key)\n",
    "    #print(\"key {}, total {}\".format(key,n))\n",
    "    total_samples += n\n",
    "    class_samples[key] = n\n",
    "print(total_samples)\n",
    "proportions = []\n",
    "for key in the_keys:\n",
    "    proportion = round(class_samples[key]*1.0/total_samples,2)\n",
    "    proportions.append(proportion)\n",
    "    print(\"key {}, samples: {}, prop: {}\".format(key,class_samples[key],proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = list(range(60))+[67,68]\n",
    "row_label = 60\n",
    "dfs_all,_ = pc.split_df_discussions(df_data,.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_all,_ = pc.split_df_discussions(df_data,.0,SEED)\n",
    "X_all,y_all = pc.get_joined_data_from_df(dfs_all,filter_rows,row_label)\n",
    "np.max(proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       403\n",
      "           2       0.00      0.00      0.00       175\n",
      "           3       0.00      0.00      0.00       406\n",
      "           4       0.00      0.00      0.00        62\n",
      "           5       0.35      1.00      0.51       554\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      1600\n",
      "   macro avg       0.07      0.20      0.10      1600\n",
      "weighted avg       0.12      0.35      0.18      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CATALINA ESPINOZA\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Phase 1</th>\n",
       "      <th>Predicted Phase 2</th>\n",
       "      <th>Predicted Phase 3</th>\n",
       "      <th>Predicted Phase 4</th>\n",
       "      <th>Predicted Phase 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Phase 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phase 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phase 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phase 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phase 5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Predicted Phase 1  Predicted Phase 2  Predicted Phase 3  \\\n",
       "Phase 1                  0                  0                  0   \n",
       "Phase 2                  0                  0                  0   \n",
       "Phase 3                  0                  0                  0   \n",
       "Phase 4                  0                  0                  0   \n",
       "Phase 5                  0                  0                  0   \n",
       "\n",
       "         Predicted Phase 4  Predicted Phase 5  \n",
       "Phase 1                  0                403  \n",
       "Phase 2                  0                175  \n",
       "Phase 3                  0                406  \n",
       "Phase 4                  0                 62  \n",
       "Phase 5                  0                554  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = np.argmax(proportions)+1\n",
    "pred = [phase for i in y_all]\n",
    "labels = [\"Phase {}\".format(i) for i in range(1,6)]\n",
    "df = pd.DataFrame(confusion_matrix(y_all, pred),columns=[\"Predicted {}\".format(i) for i in labels])\n",
    "df.index = labels\n",
    "#print(\" \")\n",
    "print(classification_report(y_all, pred))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       403\n",
      "           2       0.00      0.00      0.00       175\n",
      "           3       0.00      0.00      0.00       406\n",
      "           4       0.00      0.00      0.00        62\n",
      "           5       0.35      1.00      0.51       554\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      1600\n",
      "   macro avg       0.07      0.20      0.10      1600\n",
      "weighted avg       0.12      0.35      0.18      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CATALINA ESPINOZA\\AppData\\Local\\conda\\conda\\envs\\teacher_topic_model\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_all, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = [pc.unit_vector(x) for x in y_all]\n",
    "y_pred = [pc.unit_vector(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085480814398115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum([np.square(y_pred[i]-bs[i]) for i in range(len(y_all))])/(len(y_all)*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find threshold to split two mayor proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all,y_all = pc.get_data_from_list_df(dfs_all,filter_rows,row_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.phase_classification' from 'C:\\\\Users\\\\CATALINA ESPINOZA\\\\Documents\\\\ciae\\\\Classification_IBL\\\\src\\\\phase_classification.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib \n",
    "importlib.reload(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsort_prop = np.argsort(proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_try = []\n",
    "steps = np.arange(0,1.0,0.025)\n",
    "for step in steps:\n",
    "    accuracy_try_aux = []\n",
    "    for i in range(len(y_all)):\n",
    "        test_prediction = []\n",
    "        for j in range(len(y_all[i])):\n",
    "            step_j = j*1.0/len(y_all[i])\n",
    "            if step_j > step:\n",
    "                test_prediction.append(argsort_prop[-1]+1)\n",
    "            else:\n",
    "                test_prediction.append(argsort_prop[-2]+1)\n",
    "        accuracy_try_aux.append(np.sum(confusion_matrix(y_all[i], test_prediction).diagonal())/len(y_all[i]))\n",
    "    accuracy_try.append(np.mean(accuracy_try_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.3599080476362191 0.42500000000000004\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(accuracy_try),np.max(accuracy_try),steps[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = steps[17]\n",
    "y_alls = []\n",
    "pred = []\n",
    "for i in range(len(y_all)):\n",
    "    test_prediction = []\n",
    "    for j in range(len(y_all[i])):\n",
    "        y_alls.append(y_all[i][j])    \n",
    "        step_j = j*1.0/len(y_all[i])\n",
    "        if step_j > step:\n",
    "            pred.append(argsort_prop[-1]+1)\n",
    "        else:\n",
    "            pred.append(argsort_prop[-2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pred[i]==y_alls[i] for i in range(len(y_alls))].count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.365625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "585/len(y_alls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = [pc.unit_vector(x) for x in y_alls]\n",
    "y_pred = [pc.unit_vector(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964766161036996"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum([np.square(y_pred[i]-bs[i]) for i in range(len(y_alls))])/(len(y_alls)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_1 = step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find threshold to split 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_try = []\n",
    "steps = np.arange(0,1.0,0.025)\n",
    "for step in steps:\n",
    "    accuracy_try_aux = []\n",
    "    for i in range(len(y_all)):\n",
    "        test_prediction = []\n",
    "        for j in range(len(y_all[i])):\n",
    "            step_j = j*1.0/len(y_all[i])\n",
    "            if step_j > step:\n",
    "                test_prediction.append(argsort_prop[-1]+1)\n",
    "            else:\n",
    "                test_prediction.append(1)\n",
    "        accuracy_try_aux.append(np.sum(confusion_matrix(y_all[i], test_prediction).diagonal())/len(y_all[i]))\n",
    "    accuracy_try.append(np.mean(accuracy_try_aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.4450968597394787 0.375\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(accuracy_try),np.max(accuracy_try),steps[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = steps[15]\n",
    "y_alls = []\n",
    "pred = []\n",
    "for i in range(len(y_all)):\n",
    "    test_prediction = []\n",
    "    for j in range(len(y_all[i])):\n",
    "        y_alls.append(y_all[i][j])    \n",
    "        step_j = j*1.0/len(y_all[i])\n",
    "        if step_j > step:\n",
    "            pred.append(argsort_prop[-1]+1)\n",
    "        else:\n",
    "            pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = [pc.unit_vector(x) for x in y_alls]\n",
    "y_pred = [pc.unit_vector(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7454025757937788"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum([np.square(y_pred[i]-bs[i]) for i in range(len(y_alls))])/(len(y_alls)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_2 = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path,'random_training.pickle'),'wb') as f:\n",
    "    pickle.dump(proportions,f)\n",
    "    pickle.dump(step_1,f)\n",
    "    pickle.dump(step_2,f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
